项目一
名称：Persona Assistant（数字人简历问答机器人）
时间：2025.12 – 2026.01
简介：把个人简历/文章/经历沉淀为可检索知识库，支持访客对话式了解候选人信息，输出带引用证据的回答，避免编造。

我的工作：

设计并实现 RAG 管线：数据导入 → 分段切块（按章节/句子窗口）→ 向量化 → 检索 → Rerank → 证据压缩 → 生成回答。

本地化部署：Ollama 运行 qwen2.5 系列模型；Qdrant 作为向量数据库；FastAPI 提供 /upload、/index/rebuild、/chat 等接口。

检索效果优化：引入 Hybrid Retrieval（BM25 + Dense + RRF 融合），再用 Cross-Encoder 做 chunk/句子级 rerank，显著减少“泛段落命中”。

可控输出：通过“可回答性判断 + 证据门禁 + 引用展示”机制，确保回答严格基于证据，证据不足时拒答。

技术栈：FastAPI、Qdrant、Ollama、sentence-transformers（Cross-Encoder rerank）、BM25、React/Next.js（前端）



项目二
名称：TechDoc QA（中文技术文档问答与摘要助手）
时间：2025.10 – 2025.11
简介：面向团队内部技术文档（API 说明、故障排查、周报），提供问答与“基于证据的结构化总结”，支持快速定位关键信息。

我的工作：

文档预处理与切分：按标题层级（如“背景/方案/接口/FAQ”）切段，并用句子滑窗生成 chunk，保证 chunk 内语义完整。

构建 Hybrid 检索：

BM25 负责关键词/错误码/接口名等精确命中；

Dense embedding 负责语义召回；

RRF 融合候选，提升对口语化提问的覆盖率。

精排与压缩：对 topN chunk 进行 cross-encoder rerank，再把候选句子池统一 rerank，抽取最相关证据句形成 evidence block。

生成与格式化输出：对“如何排查/对比方案/接口参数”等问题输出 checklist 或表格式要点；证据不足时返回可操作的追问建议。

技术栈：Python、Qdrant、BM25、Cross-Encoder rerank、Ollama（本地模型）、FastAPI
